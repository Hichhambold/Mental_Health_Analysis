{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"../data/Mental_Health_and_Social_Media_Balance_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_dummies(columns=[\"Gender\", \"Social_Media_Platform\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\n",
    "    'Sleep_Quality(1-10)': 'Sleep_Quality',\n",
    "    'Stress_Level(1-10)': 'Stress_Level',\n",
    "    'Exercise_Frequency(week)': 'Exercise_Frequency',\n",
    "    'Daily_Screen_Time(hrs)':'Daily_Screen_Time',\n",
    "    'Social_Media_Platform_X (Twitter)' : 'Social_Media_Platform_X',\n",
    "    'Happiness_Index(1-10)' : 'Happiness_Index'\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_clean = df.drop_nulls()\n",
    "\n",
    "X = df_clean.drop(\"Happiness_Index\", \"User_ID\").to_numpy()\n",
    "y = df_clean[\"Happiness_Index\"].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "+ Stress Level Korreliert sehr stark mit Happiness_Index : Frage ist ob man das haben will oder nicht (ähnliche Metrik meiner mng nach)\n",
    "+ Für den Tree ist Level 3 ohne und Level 4 mit Stress am besten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"Train R² Score: {train_score:.4f}\")\n",
    "print(f\"Test R² Score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature names (excluding 'User_ID' and 'Happiness_Index')\n",
    "feature_names = [name for name in df_clean.columns if name not in [\"User_ID\", \"Happiness_Index\"]]\n",
    "\n",
    "# Get coefficients from the trained model\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, coefficients)\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.title(\"Feature Importance (Linear Regression Coefficients)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=3, random_state=41)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"Train R² Score: {train_score:.4f}\")\n",
    "print(f\"Test R² Score: {test_score:.4f}\")\n",
    "\n",
    "# Compute and plot feature importances from the trained DecisionTreeRegressor\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Pair names with importances and sort descending\n",
    "feat_imp_pairs = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print top 5 features\n",
    "print(\"Top 5 features by importance:\")\n",
    "for name, imp in feat_imp_pairs[:5]:\n",
    "    print(f\"{name}: {imp:.4f}\")\n",
    "\n",
    "# Prepare plotting (largest on top)\n",
    "names_sorted, importances_sorted = zip(*feat_imp_pairs)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(names_sorted[::-1], importances_sorted[::-1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Decision Tree Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=6, random_state=41)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"Train R² Score: {train_score:.4f}\")\n",
    "print(f\"Test R² Score: {test_score:.4f}\")\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feat_imp_pairs = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 5 features by importance:\")\n",
    "for name, imp in feat_imp_pairs[:5]:\n",
    "    print(f\"{name}: {imp:.4f}\")\n",
    "\n",
    "names_sorted, importances_sorted = zip(*feat_imp_pairs)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(names_sorted[::-1], importances_sorted[::-1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eb31097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R² Score: 0.4787\n",
      "Test R² Score: 0.5552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_single = X[:, 4].reshape(-1, 1)\n",
    "X_train_single = X_train[:, 4].reshape(-1, 1)\n",
    "X_test_single = X_test[:, 4].reshape(-1, 1)\n",
    "\n",
    "model_single = LinearRegression()\n",
    "model_single.fit(X_train_single, y_train)\n",
    "\n",
    "train_r2 = model_single.score(X_train_single, y_train)\n",
    "test_r2 = model_single.score(X_test_single, y_test)\n",
    "\n",
    "print(f\"Train R² Score: {train_r2:.4f}\")\n",
    "print(f\"Test R² Score: {test_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
